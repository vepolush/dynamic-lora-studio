import os
import torch
from diffusers import StableDiffusionPipeline
from huggingface_hub import snapshot_download

MODEL_ID = "runwayml/stable-diffusion-v1-5"
MODEL_DIR = "/workspace/models/sd-1-5"

class ModelManager:
    def __init__(self):
        self.pipe = None

    def load_model(self):
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ, –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î –∑–∞ –ø–æ—Ç—Ä–µ–±–∏ —Ç–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –ø–∞–π–ø–ª–∞–π–Ω."""
        print("‚è≥ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±–∞–∑–æ–≤–æ—ó –º–æ–¥–µ–ª—ñ...")
        
        if not os.path.exists(os.path.join(MODEL_DIR, "model_index.json")):
            print(f"üì• –ú–æ–¥–µ–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è {MODEL_ID}...")
            snapshot_download(repo_id=MODEL_ID, local_dir=MODEL_DIR)
            print("‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        else:
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–Ω–∞–π–¥–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ.")

        print("üöÄ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ —É VRAM (GPU)...")
        self.pipe = StableDiffusionPipeline.from_pretrained(
            MODEL_DIR,
            torch_dtype=torch.float16,
            safety_checker=None
        )
        self.pipe.to("cuda") # –ü–µ—Ä–µ–Ω–æ—Å–∏–º–æ –Ω–∞ –≤—ñ–¥–µ–æ–∫–∞—Ä—Ç—É
        print("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó!")

    def generate(self, prompt: str, steps: int, guidance_scale: float):
        """–ë–∞–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó (–ø–æ–∫–∏ –±–µ–∑ LoRA)"""
        if self.pipe is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞!")
        
        result = self.pipe(
            prompt=prompt,
            num_inference_steps=steps,
            guidance_scale=guidance_scale
        )
        return result.images[0]

ml_manager = ModelManager()